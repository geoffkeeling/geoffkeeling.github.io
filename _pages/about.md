---
permalink: /
title: "Geoff Keeling"
excerpt: "Staff Research Scientist, Google"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Staff Research Scientist and philosopher at Google. I work on the ethical and societal impacts of artificial general intelligence including questions about [alignment](https://link.springer.com/article/10.1007/s11098-025-02300-4?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20250330&utm_content=10.1007/s11098-025-02300-4), [consciousness](https://arxiv.org/pdf/2411.02432), [mainipulation](https://arxiv.org/pdf/2404.15058), and [human-AI relationships](https://ojs.aaai.org/index.php/AIES/article/view/31694).

I co-led the 2024 Google DeepMind report on the [Ethics of Advanced AI Assistants](https://arxiv.org/pdf/2404.16244), articulating a research agenda for assessing the ethical dimensions of increasingly agentic AI assistants. The report was cited over [100 times](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_k8b6mYAAAAJ&citation_for_view=_k8b6mYAAAAJ:1sJd4Hv_s6UC) in its first year including in the [International Scientific Report on the Safety of Advanced AI](https://arxiv.org/pdf/2412.05282) led by Yoshua Bengio, while also being covered by global outlets such as [WIRED](https://www.wired.com/story/prepare-to-get-manipulated-by-emotionally-expressive-chatbots/) and [the Information](https://www.theinformation.com/articles/why-google-and-openai-dont-see-eye-to-eye-on-voice-assistants). I also co-led Googleâ€™s first [empirical study](https://arxiv.org/pdf/2411.02432) on machine sentience in collaboration with [Jonathan Birch](https://personal.lse.ac.uk/birchj1/) at the London School of Economics. Our research received broad media coverage including feature articles in [Scientific American](https://www.scientificamerican.com/article/could-inflicting-pain-test-ai-for-sentience/) and [Futurism](https://futurism.com/scientists-experiment-with-subjecting-ai-to-pain).

In addition to my role at Google, I am a Fellow at the [Institute of Philosophy](https://philosophy.sas.ac.uk/) in the School of Advanced Study at the University of London, and an Associate Fellow at the [Leverhulme Centre for the Future of Intelligence](http://lcfi.ac.uk) at the University of Cambridge. Prior to Google, I was a Postdoctoral Fellow at Stanford University, based in the [Institute for Human-Centered AI](https://hai.stanford.edu/) and the [McCoy Family Center for Ethics in Society](https://ethicsinsociety.stanford.edu/). With [Alex Tamkin](https://www.alextamkin.com/), I successfully lobbied for and co-led the AI Safety chapter of the 2021 report on the [Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258/pdf). The report has over [5,000](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_k8b6mYAAAAJ&citation_for_view=_k8b6mYAAAAJ:roLk4NBRz8UC) citations and was covered by both [Forbes](https://www.forbes.com/sites/arunshastri/2022/08/16/building-on-foundation-models-ensure-they-are-trustworthy/?sh=55421c610c3b) and the [Economist](https://www.economist.com/interactive/briefing/2022/06/11/huge-foundation-models-are-turbo-charging-ai-progress). 

[Here](https://geoffkeeling.github.io/files/CV.pdf) is my CV.

![GeoffKeeling](https://geoffkeeling.github.io/images/bio-photo.jpg)

Image: [Kasper Dalkarl](https://www.kasperdalkarl.com/)
